{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "ad79338f-5db0-4d7e-bb49-2ba2a50486d6",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Pytorch Implementation of Smell Prediction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1dd5936f-1341-4e49-b7ba-31885874c312",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "from os.path import isfile, join\n",
    "from os import listdir\n",
    "from copy import deepcopy\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import accuracy_score\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from torch.utils.data import Dataset, DataLoader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2e4b192-5698-42ec-823d-5ba0560db9b1",
   "metadata": {},
   "source": [
    "Below we hide a bunch of functions for preprocessing the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "956d1d86-c950-4841-bbdd-bf656d807fa6",
   "metadata": {
    "jupyter": {
     "source_hidden": true
    },
    "tags": [
     "hide-cell"
    ]
   },
   "outputs": [],
   "source": [
    "def answer_preprocess_sensor(df_list):\n",
    "    \"\"\"\n",
    "    This function is the answer of task 5.\n",
    "    Preprocess sensor data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_list : list of pandas.DataFrame\n",
    "        A list of data frames that contain sensor data from multiple stations.\n",
    "         \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        The preprocessed sensor data.\n",
    "    \"\"\"\n",
    "    # Resample all the data frames.\n",
    "    df_resample_list = []\n",
    "    for df in df_list:\n",
    "        # Convert the timestamp to datetime.\n",
    "        df.index = pd.to_datetime(df.index, unit=\"s\", utc=True)\n",
    "        # Resample the timestamps by hour and average all the previous values.\n",
    "        # Because we want data from the past, so label need to be \"right\".\n",
    "        df_resample_list.append(df.resample(\"60Min\", label=\"right\").mean())\n",
    "    \n",
    "    # Merge all data frames.\n",
    "    df = df_resample_list.pop(0)\n",
    "    index_name = df.index.name\n",
    "    while len(df_resample_list) != 0:\n",
    "        # We need to use outer merging since we want to preserve data from both data frames.\n",
    "        df = pd.merge_ordered(df, df_resample_list.pop(0), on=df.index.name, how=\"outer\", fill_method=None)\n",
    "        # Move the datetime column to index\n",
    "        df = df.set_index(index_name)\n",
    "\n",
    "    # Fill in the missing data with value -1.\n",
    "    df = df.fillna(-1)\n",
    "    return df\n",
    "\n",
    "\n",
    "def answer_preprocess_smell(df):\n",
    "    \"\"\"\n",
    "    This function is the answer of task 4.\n",
    "    Preprocess smell data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The raw smell reports data.\n",
    "         \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        The preprocessed smell data.\n",
    "    \"\"\"\n",
    "    # Copy the dataframe to avoid editing the original one.\n",
    "    df = df.copy(deep=True)\n",
    "    \n",
    "    # Drop the columns that we do not need.\n",
    "    df = df.drop(columns=[\"feelings_symptoms\", \"smell_description\", \"zipcode\"])\n",
    "    \n",
    "    # Select only the reports within the range of 3 and 5.\n",
    "    df = df[(df[\"smell_value\"]>=3)&(df[\"smell_value\"]<=5)]\n",
    "    \n",
    "    # Convert the timestamp to datetime.\n",
    "    df.index = pd.to_datetime(df.index, unit=\"s\", utc=True)\n",
    "\n",
    "    # Resample the timestamps by hour and sum up all the future values.\n",
    "    # Because we want data from the future, so label need to be \"left\".\n",
    "    df = df.resample(\"60Min\", label=\"left\").sum()\n",
    "    \n",
    "    # Fill in the missing data with value 0.\n",
    "    df = df.fillna(0)\n",
    "    return df\n",
    "\n",
    "\n",
    "def answer_sum_current_and_future_data(df, n_hr=0):\n",
    "    \"\"\"\n",
    "    This function is the answer of task 6.\n",
    "    Sum up data in the current and future hours.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The preprocessed smell data.\n",
    "    n_hr : int\n",
    "         Number of hours that we want to sum up the future smell data.\n",
    "         \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        The transformed smell data.\n",
    "    \"\"\"\n",
    "    # Copy data frame to prevent editing the original one.\n",
    "    df = df.copy(deep=True)\n",
    "    \n",
    "    # Fast return if n_hr is 0\n",
    "    if n_hr == 0: return df\n",
    "    \n",
    "    # Sum up all smell_values in future hours.\n",
    "    # The rolling function only works for summing up previous values.\n",
    "    # So we need to shift back to get the value in the future.\n",
    "    # Be careful that we need to add 1 to the rolling window size.\n",
    "    # Becasue window size 1 means only using the current data.\n",
    "    # Parameter \"closed\" need to be \"right\" because we want the current data.\n",
    "    df = df.rolling(n_hr+1, min_periods=1, closed=\"right\").sum().shift(-1*n_hr)\n",
    "    \n",
    "    # Delete the last n_hr rows.\n",
    "    # These n_hr rows have wrong data due to data shifting.\n",
    "    df = df.iloc[:-1*n_hr]\n",
    "    return df\n",
    "\n",
    "\n",
    "def insert_previous_data_to_cols(df, n_hr=0):\n",
    "    \"\"\"\n",
    "    Insert columns to indicate the data from the previous hours.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The preprocessed sensor data.\n",
    "    n_hr : int\n",
    "        Number of hours that we want to insert the previous sensor data.\n",
    "         \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        The transformed sensor data.\n",
    "    \"\"\"\n",
    "    # Copy data frame to prevent editing the original one.\n",
    "    df = df.copy(deep=True)\n",
    "\n",
    "    # Add the data from the previous hours.\n",
    "    df_all = []\n",
    "    for h in range(1, n_hr + 1):\n",
    "        # Shift the data frame to get previous data.\n",
    "        df_pre = df.shift(h)\n",
    "        # Edit the name to indicate it is previous data.\n",
    "        # The orginal data frame already has data from the previous 1 hour.\n",
    "        # (as indicated in the preprocessing phase of sensor data)\n",
    "        # So we need to add 1 here.\n",
    "        df_pre.columns += \"_pre_\" + str(h+1) + \"h\"\n",
    "        # Add the data to an array for merging.\n",
    "        df_all.append(df_pre)\n",
    "\n",
    "    # Rename the columns in the original data frame.\n",
    "    # The orginal data frame already has data from the previous 1 hour.\n",
    "    # (as indicated in the preprocessing phase of sensor data)\n",
    "    df.columns += \"_pre_1h\"\n",
    "\n",
    "    # Merge all data.\n",
    "    df_merge = df\n",
    "    for d in df_all:\n",
    "        # The join function merges dataframes by index.\n",
    "        df_merge = df_merge.join(d)\n",
    "        \n",
    "    # Delete the first n_hr rows.\n",
    "    # These n_hr rows have no data due to data shifting.\n",
    "    df_merge = df_merge.iloc[n_hr:]\n",
    "    return df_merge\n",
    "\n",
    "\n",
    "def convert_wind_direction(df):\n",
    "    \"\"\"\n",
    "    Convert wind directions to sine and cosine components.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df : pandas.DataFrame\n",
    "        The data frame that contains the wind direction data.\n",
    "         \n",
    "    Returns\n",
    "    -------\n",
    "    pandas.DataFrame\n",
    "        The transformed data frame.\n",
    "    \"\"\"\n",
    "    # Copy data frame to prevent editing the original one.\n",
    "    df_cp = df.copy(deep=True)\n",
    "    \n",
    "    # Convert columns with wind directions.\n",
    "    for c in df.columns:\n",
    "        if \"SONICWD_DEG\" in c:\n",
    "            df_c = df[c]\n",
    "            df_c_cos = np.cos(np.deg2rad(df_c))\n",
    "            df_c_sin = np.sin(np.deg2rad(df_c))\n",
    "            df_c_cos.name += \"_cosine\"\n",
    "            df_c_sin.name += \"_sine\"\n",
    "            df_cp.drop([c], axis=1, inplace=True)\n",
    "            df_cp[df_c_cos.name] = df_c_cos\n",
    "            df_cp[df_c_sin.name] = df_c_sin\n",
    "    return df_cp\n",
    "\n",
    "\n",
    "def compute_feature_label(df_smell, df_sensor, b_hr_sensor=0, f_hr_smell=0):\n",
    "    \"\"\"\n",
    "    Compute features and labels from the smell and sensor data.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    df_smell : pandas.DataFrame\n",
    "        The preprocessed smell data.\n",
    "    df_sensor : pandas.DataFrame\n",
    "        The preprocessed sensor data.\n",
    "    b_hr_sensor : int\n",
    "        Number of hours that we want to insert the previous sensor data.\n",
    "    f_hr_smell : int\n",
    "        Number of hours that we want to sum up the future smell data.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    df_x : pandas.DataFrame\n",
    "        The features that we want to use for modeling.\n",
    "    df_y : pandas.DataFrame\n",
    "        The labels that we want to use for modeling.\n",
    "    \"\"\"\n",
    "    # Copy data frames to prevent editing the original ones.\n",
    "    df_smell = df_smell.copy(deep=True)\n",
    "    df_sensor = df_sensor.copy(deep=True)\n",
    "    \n",
    "    # Replace -1 values in sensor data to NaN\n",
    "    df_sensor[df_sensor==-1] = np.nan\n",
    "    \n",
    "    # Convert all wind directions.\n",
    "    df_sensor = convert_wind_direction(df_sensor)\n",
    "    \n",
    "    # Scale sensor data and fill in missing values\n",
    "    df_sensor = (df_sensor - df_sensor.mean()) / df_sensor.std()\n",
    "    df_sensor = df_sensor.round(6)\n",
    "    df_sensor = df_sensor.fillna(-1)\n",
    "    \n",
    "    # Insert previous sensor data as features.\n",
    "    # Noice that the df_sensor is already using the previous data.\n",
    "    # So b_hr_sensor=0 means using data from the previous 1 hour.\n",
    "    # And b_hr_sensor=n means using data from the previous n+1 hours.\n",
    "    df_sensor = insert_previous_data_to_cols(df_sensor, b_hr_sensor)\n",
    "    \n",
    "    # Sum up current and future smell values as label.\n",
    "    # Notice that the df_smell is already the data from the future 1 hour.\n",
    "    # (as indicated in the preprocessing phase of smell data)\n",
    "    # So f_hr_smell=0 means using data from the future 1 hour.\n",
    "    # And f_hr_smell=n means using data from the future n+1 hours.\n",
    "    df_smell = answer_sum_current_and_future_data(df_smell, f_hr_smell)\n",
    "    \n",
    "    # Add suffix to the column name of the smell data to prevent confusion.\n",
    "    # See the description above for the reason of adding 1 to the f_hr_smell.\n",
    "    df_smell.columns += \"_future_\" + str(f_hr_smell+1) + \"h\"\n",
    "    \n",
    "    # We need to first merge these two timestamps based on the available data.\n",
    "    # In this way, we synchronize the time stamps in the sensor and smell data.\n",
    "    # This also means that the sensor and smell data have the same number of data points.\n",
    "    df = pd.merge_ordered(df_sensor.reset_index(), df_smell.reset_index(), on=df_smell.index.name, how=\"inner\", fill_method=None)\n",
    "    \n",
    "    # Sanity check: there should be no missing data.\n",
    "    assert df.isna().sum().sum() == 0, \"Error! There is missing data.\"\n",
    "    \n",
    "    # Separate features (x) and labels (y).\n",
    "    df_x = df[df_sensor.columns]\n",
    "    df_y = df[df_smell.columns]\n",
    "    \n",
    "    # Add the hour of day and the day of week.\n",
    "    dow_radian = df[\"EpochTime\"].dt.dayofweek.copy(deep=True) * 2 * np.pi / 6.0\n",
    "    tod_radian = df[\"EpochTime\"].dt.hour.copy(deep=True) * 2 * np.pi / 23.0\n",
    "    df_x.loc[:,\"day_of_week_sine\"] = np.sin(dow_radian)\n",
    "    df_x.loc[:,\"day_of_week_cosine\"] = np.cos(dow_radian)\n",
    "    df_x.loc[:,\"hour_of_day_sine\"] = np.sin(tod_radian)\n",
    "    df_x.loc[:,\"hour_of_day_cosine\"] = np.cos(tod_radian)\n",
    "    return df_x, df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a3c3ac86-c7dd-46ca-973b-844a32cf7cb7",
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/xr/ddxdh8x16q53_r8yf2zj9m600000gn/T/ipykernel_13861/4187725043.py:261: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: https://pandas.pydata.org/pandas-docs/stable/user_guide/indexing.html#returning-a-view-versus-a-copy\n",
      "  df_x.loc[:,\"day_of_week_sine\"] = np.sin(dow_radian)\n"
     ]
    }
   ],
   "source": [
    "# Load and preprocess sensor data\n",
    "path = \"smellpgh-v1/esdr_raw\"\n",
    "list_of_files = [f for f in listdir(path) if isfile(join(path, f))]\n",
    "sensor_raw_list = []\n",
    "for f in list_of_files:\n",
    "    sensor_raw_list.append(pd.read_csv(join(path, f)).set_index(\"EpochTime\"))\n",
    "df_sensor = answer_preprocess_sensor(sensor_raw_list)\n",
    "\n",
    "# Load and preprocess smell data\n",
    "smell_raw = pd.read_csv(\"smellpgh-v1/smell_raw.csv\").set_index(\"EpochTime\")\n",
    "df_smell = answer_preprocess_smell(smell_raw)\n",
    "\n",
    "# Compute features and labels\n",
    "df_x, df_y = compute_feature_label(df_smell, df_sensor, b_hr_sensor=2, f_hr_smell=7)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "06cbb715-48f2-419f-89a1-0b9593a34290",
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>3.feed_1.SO2_PPM_pre_1h</th>\n",
       "      <th>3.feed_1.H2S_PPM_pre_1h</th>\n",
       "      <th>3.feed_1.SIGTHETA_DEG_pre_1h</th>\n",
       "      <th>3.feed_1.SONICWS_MPH_pre_1h</th>\n",
       "      <th>3.feed_23.CO_PPM_pre_1h</th>\n",
       "      <th>3.feed_23.PM10_UG_M3_pre_1h</th>\n",
       "      <th>3.feed_29.PM10_UG_M3_pre_1h</th>\n",
       "      <th>3.feed_29.PM25_UG_M3_pre_1h</th>\n",
       "      <th>3.feed_11067.CO_PPB..3.feed_43.CO_PPB_pre_1h</th>\n",
       "      <th>3.feed_11067.NO2_PPB..3.feed_43.NO2_PPB_pre_1h</th>\n",
       "      <th>...</th>\n",
       "      <th>3.feed_28.SONICWD_DEG_cosine_pre_3h</th>\n",
       "      <th>3.feed_28.SONICWD_DEG_sine_pre_3h</th>\n",
       "      <th>3.feed_26.SONICWD_DEG_cosine_pre_3h</th>\n",
       "      <th>3.feed_26.SONICWD_DEG_sine_pre_3h</th>\n",
       "      <th>3.feed_3.SONICWD_DEG_cosine_pre_3h</th>\n",
       "      <th>3.feed_3.SONICWD_DEG_sine_pre_3h</th>\n",
       "      <th>day_of_week_sine</th>\n",
       "      <th>day_of_week_cosine</th>\n",
       "      <th>hour_of_day_sine</th>\n",
       "      <th>hour_of_day_cosine</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>-0.273112</td>\n",
       "      <td>-0.403688</td>\n",
       "      <td>-1.520058</td>\n",
       "      <td>-0.599075</td>\n",
       "      <td>-0.388936</td>\n",
       "      <td>-0.777225</td>\n",
       "      <td>-0.406466</td>\n",
       "      <td>-0.395826</td>\n",
       "      <td>-0.716551</td>\n",
       "      <td>-0.585693</td>\n",
       "      <td>...</td>\n",
       "      <td>0.279097</td>\n",
       "      <td>1.746934</td>\n",
       "      <td>-0.383942</td>\n",
       "      <td>1.929446</td>\n",
       "      <td>-0.542867</td>\n",
       "      <td>1.331119</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>-2.449294e-16</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>-0.273112</td>\n",
       "      <td>-0.403688</td>\n",
       "      <td>-1.433654</td>\n",
       "      <td>-0.684709</td>\n",
       "      <td>-0.388936</td>\n",
       "      <td>-0.690974</td>\n",
       "      <td>0.007500</td>\n",
       "      <td>-0.305936</td>\n",
       "      <td>-0.426597</td>\n",
       "      <td>0.488014</td>\n",
       "      <td>...</td>\n",
       "      <td>1.089779</td>\n",
       "      <td>1.481480</td>\n",
       "      <td>0.945548</td>\n",
       "      <td>1.350182</td>\n",
       "      <td>0.512949</td>\n",
       "      <td>1.355712</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.000000e+00</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>-0.273112</td>\n",
       "      <td>-0.403688</td>\n",
       "      <td>1.142731</td>\n",
       "      <td>-0.941610</td>\n",
       "      <td>0.147335</td>\n",
       "      <td>-0.173473</td>\n",
       "      <td>-0.147737</td>\n",
       "      <td>-0.216045</td>\n",
       "      <td>-0.444787</td>\n",
       "      <td>0.829648</td>\n",
       "      <td>...</td>\n",
       "      <td>0.799733</td>\n",
       "      <td>1.640186</td>\n",
       "      <td>0.726159</td>\n",
       "      <td>1.603583</td>\n",
       "      <td>0.537757</td>\n",
       "      <td>1.347897</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>2.697968e-01</td>\n",
       "      <td>0.962917</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>-0.273112</td>\n",
       "      <td>-0.403688</td>\n",
       "      <td>-0.082623</td>\n",
       "      <td>-0.941610</td>\n",
       "      <td>0.147335</td>\n",
       "      <td>-0.432224</td>\n",
       "      <td>-0.302974</td>\n",
       "      <td>-0.216045</td>\n",
       "      <td>-0.796641</td>\n",
       "      <td>0.081306</td>\n",
       "      <td>...</td>\n",
       "      <td>0.960380</td>\n",
       "      <td>1.562966</td>\n",
       "      <td>1.185067</td>\n",
       "      <td>0.816616</td>\n",
       "      <td>0.512949</td>\n",
       "      <td>1.355712</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>5.195840e-01</td>\n",
       "      <td>0.854419</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>-0.273112</td>\n",
       "      <td>-0.403688</td>\n",
       "      <td>1.527618</td>\n",
       "      <td>-0.984426</td>\n",
       "      <td>0.147335</td>\n",
       "      <td>-0.259723</td>\n",
       "      <td>-0.458211</td>\n",
       "      <td>-0.485717</td>\n",
       "      <td>-0.762976</td>\n",
       "      <td>-0.504352</td>\n",
       "      <td>...</td>\n",
       "      <td>1.623480</td>\n",
       "      <td>0.780539</td>\n",
       "      <td>1.225168</td>\n",
       "      <td>0.602477</td>\n",
       "      <td>0.659294</td>\n",
       "      <td>1.303117</td>\n",
       "      <td>0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>7.308360e-01</td>\n",
       "      <td>0.682553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16746</th>\n",
       "      <td>-0.273112</td>\n",
       "      <td>-0.403688</td>\n",
       "      <td>0.011635</td>\n",
       "      <td>-0.128090</td>\n",
       "      <td>-0.925207</td>\n",
       "      <td>-0.604724</td>\n",
       "      <td>-0.561703</td>\n",
       "      <td>-0.575607</td>\n",
       "      <td>0.529598</td>\n",
       "      <td>-0.748376</td>\n",
       "      <td>...</td>\n",
       "      <td>1.707841</td>\n",
       "      <td>0.380565</td>\n",
       "      <td>1.119099</td>\n",
       "      <td>-0.254164</td>\n",
       "      <td>1.210281</td>\n",
       "      <td>-0.738344</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-9.976688e-01</td>\n",
       "      <td>-0.068242</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16747</th>\n",
       "      <td>-0.273112</td>\n",
       "      <td>-0.403688</td>\n",
       "      <td>0.443651</td>\n",
       "      <td>0.000361</td>\n",
       "      <td>-0.925207</td>\n",
       "      <td>-0.690974</td>\n",
       "      <td>-0.406466</td>\n",
       "      <td>-0.665498</td>\n",
       "      <td>0.662087</td>\n",
       "      <td>-0.292864</td>\n",
       "      <td>...</td>\n",
       "      <td>1.693445</td>\n",
       "      <td>0.048275</td>\n",
       "      <td>1.098706</td>\n",
       "      <td>-0.303805</td>\n",
       "      <td>1.327922</td>\n",
       "      <td>-0.583204</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-9.790841e-01</td>\n",
       "      <td>0.203456</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16748</th>\n",
       "      <td>-0.273112</td>\n",
       "      <td>-0.403688</td>\n",
       "      <td>0.443651</td>\n",
       "      <td>-0.256540</td>\n",
       "      <td>-0.925207</td>\n",
       "      <td>-0.604724</td>\n",
       "      <td>-0.458211</td>\n",
       "      <td>-0.575607</td>\n",
       "      <td>0.181817</td>\n",
       "      <td>-0.862254</td>\n",
       "      <td>...</td>\n",
       "      <td>1.489886</td>\n",
       "      <td>-0.500401</td>\n",
       "      <td>0.609087</td>\n",
       "      <td>-0.931955</td>\n",
       "      <td>0.798657</td>\n",
       "      <td>-1.062282</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-8.878852e-01</td>\n",
       "      <td>0.460065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16749</th>\n",
       "      <td>-0.273112</td>\n",
       "      <td>-0.403688</td>\n",
       "      <td>0.270844</td>\n",
       "      <td>-0.085273</td>\n",
       "      <td>-0.925207</td>\n",
       "      <td>-0.518474</td>\n",
       "      <td>-0.302974</td>\n",
       "      <td>-0.575607</td>\n",
       "      <td>0.856204</td>\n",
       "      <td>-0.439279</td>\n",
       "      <td>...</td>\n",
       "      <td>1.402368</td>\n",
       "      <td>-0.626362</td>\n",
       "      <td>0.237194</td>\n",
       "      <td>-1.124325</td>\n",
       "      <td>0.706601</td>\n",
       "      <td>-1.107672</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-7.308360e-01</td>\n",
       "      <td>0.682553</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16750</th>\n",
       "      <td>-0.273112</td>\n",
       "      <td>-0.403688</td>\n",
       "      <td>-0.341833</td>\n",
       "      <td>0.085995</td>\n",
       "      <td>-0.925207</td>\n",
       "      <td>-0.432224</td>\n",
       "      <td>-0.406466</td>\n",
       "      <td>-0.395826</td>\n",
       "      <td>0.798647</td>\n",
       "      <td>-0.309133</td>\n",
       "      <td>...</td>\n",
       "      <td>0.581575</td>\n",
       "      <td>-1.153330</td>\n",
       "      <td>-0.684058</td>\n",
       "      <td>-1.060369</td>\n",
       "      <td>-0.161757</td>\n",
       "      <td>-1.243870</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>-5.195840e-01</td>\n",
       "      <td>0.854419</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16751 rows × 148 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       3.feed_1.SO2_PPM_pre_1h  3.feed_1.H2S_PPM_pre_1h  \\\n",
       "0                    -0.273112                -0.403688   \n",
       "1                    -0.273112                -0.403688   \n",
       "2                    -0.273112                -0.403688   \n",
       "3                    -0.273112                -0.403688   \n",
       "4                    -0.273112                -0.403688   \n",
       "...                        ...                      ...   \n",
       "16746                -0.273112                -0.403688   \n",
       "16747                -0.273112                -0.403688   \n",
       "16748                -0.273112                -0.403688   \n",
       "16749                -0.273112                -0.403688   \n",
       "16750                -0.273112                -0.403688   \n",
       "\n",
       "       3.feed_1.SIGTHETA_DEG_pre_1h  3.feed_1.SONICWS_MPH_pre_1h  \\\n",
       "0                         -1.520058                    -0.599075   \n",
       "1                         -1.433654                    -0.684709   \n",
       "2                          1.142731                    -0.941610   \n",
       "3                         -0.082623                    -0.941610   \n",
       "4                          1.527618                    -0.984426   \n",
       "...                             ...                          ...   \n",
       "16746                      0.011635                    -0.128090   \n",
       "16747                      0.443651                     0.000361   \n",
       "16748                      0.443651                    -0.256540   \n",
       "16749                      0.270844                    -0.085273   \n",
       "16750                     -0.341833                     0.085995   \n",
       "\n",
       "       3.feed_23.CO_PPM_pre_1h  3.feed_23.PM10_UG_M3_pre_1h  \\\n",
       "0                    -0.388936                    -0.777225   \n",
       "1                    -0.388936                    -0.690974   \n",
       "2                     0.147335                    -0.173473   \n",
       "3                     0.147335                    -0.432224   \n",
       "4                     0.147335                    -0.259723   \n",
       "...                        ...                          ...   \n",
       "16746                -0.925207                    -0.604724   \n",
       "16747                -0.925207                    -0.690974   \n",
       "16748                -0.925207                    -0.604724   \n",
       "16749                -0.925207                    -0.518474   \n",
       "16750                -0.925207                    -0.432224   \n",
       "\n",
       "       3.feed_29.PM10_UG_M3_pre_1h  3.feed_29.PM25_UG_M3_pre_1h  \\\n",
       "0                        -0.406466                    -0.395826   \n",
       "1                         0.007500                    -0.305936   \n",
       "2                        -0.147737                    -0.216045   \n",
       "3                        -0.302974                    -0.216045   \n",
       "4                        -0.458211                    -0.485717   \n",
       "...                            ...                          ...   \n",
       "16746                    -0.561703                    -0.575607   \n",
       "16747                    -0.406466                    -0.665498   \n",
       "16748                    -0.458211                    -0.575607   \n",
       "16749                    -0.302974                    -0.575607   \n",
       "16750                    -0.406466                    -0.395826   \n",
       "\n",
       "       3.feed_11067.CO_PPB..3.feed_43.CO_PPB_pre_1h  \\\n",
       "0                                         -0.716551   \n",
       "1                                         -0.426597   \n",
       "2                                         -0.444787   \n",
       "3                                         -0.796641   \n",
       "4                                         -0.762976   \n",
       "...                                             ...   \n",
       "16746                                      0.529598   \n",
       "16747                                      0.662087   \n",
       "16748                                      0.181817   \n",
       "16749                                      0.856204   \n",
       "16750                                      0.798647   \n",
       "\n",
       "       3.feed_11067.NO2_PPB..3.feed_43.NO2_PPB_pre_1h  ...  \\\n",
       "0                                           -0.585693  ...   \n",
       "1                                            0.488014  ...   \n",
       "2                                            0.829648  ...   \n",
       "3                                            0.081306  ...   \n",
       "4                                           -0.504352  ...   \n",
       "...                                               ...  ...   \n",
       "16746                                       -0.748376  ...   \n",
       "16747                                       -0.292864  ...   \n",
       "16748                                       -0.862254  ...   \n",
       "16749                                       -0.439279  ...   \n",
       "16750                                       -0.309133  ...   \n",
       "\n",
       "       3.feed_28.SONICWD_DEG_cosine_pre_3h  3.feed_28.SONICWD_DEG_sine_pre_3h  \\\n",
       "0                                 0.279097                           1.746934   \n",
       "1                                 1.089779                           1.481480   \n",
       "2                                 0.799733                           1.640186   \n",
       "3                                 0.960380                           1.562966   \n",
       "4                                 1.623480                           0.780539   \n",
       "...                                    ...                                ...   \n",
       "16746                             1.707841                           0.380565   \n",
       "16747                             1.693445                           0.048275   \n",
       "16748                             1.489886                          -0.500401   \n",
       "16749                             1.402368                          -0.626362   \n",
       "16750                             0.581575                          -1.153330   \n",
       "\n",
       "       3.feed_26.SONICWD_DEG_cosine_pre_3h  3.feed_26.SONICWD_DEG_sine_pre_3h  \\\n",
       "0                                -0.383942                           1.929446   \n",
       "1                                 0.945548                           1.350182   \n",
       "2                                 0.726159                           1.603583   \n",
       "3                                 1.185067                           0.816616   \n",
       "4                                 1.225168                           0.602477   \n",
       "...                                    ...                                ...   \n",
       "16746                             1.119099                          -0.254164   \n",
       "16747                             1.098706                          -0.303805   \n",
       "16748                             0.609087                          -0.931955   \n",
       "16749                             0.237194                          -1.124325   \n",
       "16750                            -0.684058                          -1.060369   \n",
       "\n",
       "       3.feed_3.SONICWD_DEG_cosine_pre_3h  3.feed_3.SONICWD_DEG_sine_pre_3h  \\\n",
       "0                               -0.542867                          1.331119   \n",
       "1                                0.512949                          1.355712   \n",
       "2                                0.537757                          1.347897   \n",
       "3                                0.512949                          1.355712   \n",
       "4                                0.659294                          1.303117   \n",
       "...                                   ...                               ...   \n",
       "16746                            1.210281                         -0.738344   \n",
       "16747                            1.327922                         -0.583204   \n",
       "16748                            0.798657                         -1.062282   \n",
       "16749                            0.706601                         -1.107672   \n",
       "16750                           -0.161757                         -1.243870   \n",
       "\n",
       "       day_of_week_sine  day_of_week_cosine  hour_of_day_sine  \\\n",
       "0              0.000000                 1.0     -2.449294e-16   \n",
       "1              0.866025                 0.5      0.000000e+00   \n",
       "2              0.866025                 0.5      2.697968e-01   \n",
       "3              0.866025                 0.5      5.195840e-01   \n",
       "4              0.866025                 0.5      7.308360e-01   \n",
       "...                 ...                 ...               ...   \n",
       "16746         -0.866025                 0.5     -9.976688e-01   \n",
       "16747         -0.866025                 0.5     -9.790841e-01   \n",
       "16748         -0.866025                 0.5     -8.878852e-01   \n",
       "16749         -0.866025                 0.5     -7.308360e-01   \n",
       "16750         -0.866025                 0.5     -5.195840e-01   \n",
       "\n",
       "       hour_of_day_cosine  \n",
       "0                1.000000  \n",
       "1                1.000000  \n",
       "2                0.962917  \n",
       "3                0.854419  \n",
       "4                0.682553  \n",
       "...                   ...  \n",
       "16746           -0.068242  \n",
       "16747            0.203456  \n",
       "16748            0.460065  \n",
       "16749            0.682553  \n",
       "16750            0.854419  \n",
       "\n",
       "[16751 rows x 148 columns]"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "bbad862c-5a3f-4024-a354-8f015821cd07",
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>smell_value_future_8h</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>8.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16746</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16747</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16748</th>\n",
       "      <td>6.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16749</th>\n",
       "      <td>3.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16750</th>\n",
       "      <td>11.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>16751 rows × 1 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       smell_value_future_8h\n",
       "0                        8.0\n",
       "1                        5.0\n",
       "2                        5.0\n",
       "3                        5.0\n",
       "4                        5.0\n",
       "...                      ...\n",
       "16746                    6.0\n",
       "16747                    6.0\n",
       "16748                    6.0\n",
       "16749                    3.0\n",
       "16750                   11.0\n",
       "\n",
       "[16751 rows x 1 columns]"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d9ef1541",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Set random seed for reproducibility\n",
    "torch.manual_seed(42)\n",
    "\n",
    "# Load data\n",
    "feature = df_x[df_x.columns].to_numpy()\n",
    "label = (df_y>=40).astype(int)['smell_value_future_8h'].to_numpy()\n",
    "\n",
    "# Create the dataset object\n",
    "class SmellPittsburghDataset(Dataset):\n",
    "    def __init__(self, feature=None, label=None):\n",
    "        self.feature = feature\n",
    "        self.label = label\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.feature)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        x = self.feature[idx]\n",
    "        y = self.label[idx]\n",
    "        x = torch.from_numpy(x).float()\n",
    "        y = torch.from_numpy(np.array([y])).float()\n",
    "        return x, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "0e329627-89e9-4959-961f-27605338be0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def scorer(y_predict, y):\n",
    "    \"\"\"\n",
    "    A customized scoring function to evaluate a PyTorch classifier.\n",
    "    \n",
    "    Parameters\n",
    "    ----------\n",
    "    y_predict : torch.Tensor\n",
    "        The predicted labels.\n",
    "    y : torch.Tensor\n",
    "        The true labels.\n",
    "    \n",
    "    Returns\n",
    "    -------\n",
    "    dict of int or float\n",
    "        A dictionary of evaluation metrics.\n",
    "    \"\"\"\n",
    "    c = confusion_matrix(y, y_predict, labels=[0,1])\n",
    "    return {\"tn\": c[0,0], \"fp\": c[0,1], \"fn\": c[1,0], \"tp\": c[1,1]}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "5cb99d38-4328-4409-97c6-bc81c6024d4f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(model, criterion, optimizer, dataloader_train, dataloader_test, num_epochs=30):\n",
    "    \"\"\"Train the model.\"\"\"\n",
    "    \n",
    "    def run_one_epoch(dataloader, phase=\"train\"):\n",
    "        if phase == \"train\": model.train() # training mode\n",
    "        else: model.eval() # evaluation mode\n",
    "        c = 0 # just a counter\n",
    "        accu_loss = 0 # accumulated loss\n",
    "        accu_score = None # accumulated scores\n",
    "        # Loop the data\n",
    "        for x, y in dataloader:\n",
    "            c += 1 # increase the counter\n",
    "            y_pred = model(x)\n",
    "            loss = criterion(y_pred, y)\n",
    "            if phase == \"train\":\n",
    "                optimizer.zero_grad()\n",
    "                loss.backward()\n",
    "                optimizer.step()\n",
    "            # Store statistics for the training set\n",
    "            accu_loss += loss # add up the loss\n",
    "            y_label = (y_pred > 0.5).float()\n",
    "            score = scorer(y_label, y)\n",
    "            if accu_score is None:\n",
    "                accu_score = score\n",
    "            else:\n",
    "                for k in score:\n",
    "                    accu_score[k] += score[k]\n",
    "        # Return statistics\n",
    "        return accu_loss/c, accu_score\n",
    "    \n",
    "    def compute_statistics(score):\n",
    "        tp_fp = score[\"tp\"] + score[\"fp\"]\n",
    "        if tp_fp == 0:\n",
    "            precision = 0\n",
    "        else:\n",
    "            precision = round(score[\"tp\"]/tp_fp, 2)\n",
    "        tp_fn = score[\"tp\"] + score[\"fn\"]\n",
    "        if tp_fn == 0:\n",
    "            recall = 0\n",
    "        else:\n",
    "            recall = round(score[\"tp\"]/tp_fn, 2)\n",
    "        tp_tp_fp_fn = tp_fp + tp_fn\n",
    "        if tp_tp_fp_fn == 0:\n",
    "            f1 = 0\n",
    "        else:\n",
    "            f1 = round(2*score[\"tp\"]/tp_tp_fp_fn, 2)\n",
    "        return precision, recall, f1\n",
    "    \n",
    "    # Run one epoch\n",
    "    for epoch in range(num_epochs):\n",
    "        # Run through the entire training set\n",
    "        loss_train, score_train = run_one_epoch(dataloader_train, phase=\"train\")\n",
    "        loss_train = torch.round(loss_train, decimals=2)\n",
    "        p_train, r_train, f1_train = compute_statistics(score_train)\n",
    "        # Run through the entire testing set\n",
    "        with torch.no_grad():\n",
    "            loss_test, score_test = run_one_epoch(dataloader_test, phase=\"test\")\n",
    "        loss_test = torch.round(loss_test, decimals=2)\n",
    "        p_test, r_test, f1_test = compute_statistics(score_test)\n",
    "        # Print loss and scores\n",
    "        if ((epoch+1)%30 == 0):\n",
    "            print(f\"-\"*10)\n",
    "            print(f\"Epoch [{epoch+1}/{num_epochs}]\")\n",
    "            print(f\"Training loss: {loss_train:.4f}, prevision: {p_train:.2f}, recall: {r_train:.2f}, f1: {f1_train:.2f}\")\n",
    "            print(f\"Training evaluation: {score_train}\")\n",
    "            print(f\"Testing loss: {loss_test:.4f}, prevision: {p_test:.2f}, recall: {r_test:.2f}, f1: {f1_test:.2f}\")\n",
    "            print(f\"Testing evaluation: {score_test}\")\n",
    "    \n",
    "    # Return statistics\n",
    "    return p_test, r_test, f1_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "32089821-e0e6-4cc1-8517-dc73dcea7de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define neural network model\n",
    "class DeepLogisticRegression(nn.Module):\n",
    "    def __init__(self, input_size, hidden_size=64, output_size=1):\n",
    "        super(DeepLogisticRegression, self).__init__()\n",
    "        self.linear1 = nn.Linear(input_size, hidden_size)\n",
    "        self.relu = nn.ReLU()\n",
    "        self.linear2 = nn.Linear(hidden_size, output_size)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.linear1(x)\n",
    "        out = self.relu(out)\n",
    "        out = self.linear2(out)\n",
    "        out = self.sigmoid(out)\n",
    "        return out"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "455c20f7-2ab4-40c0-ab99-9a4a12900c1a",
   "metadata": {
    "tags": [
     "output_scroll"
    ]
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Split: 0\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 0.98, recall: 0.97, f1: 0.97\n",
      "Training evaluation: {'tn': 7363, 'fp': 11, 'fn': 21, 'tp': 605}\n",
      "Testing loss: 0.1800, prevision: 0.83, recall: 0.71, f1: 0.77\n",
      "Testing evaluation: {'tn': 144, 'fp': 3, 'fn': 6, 'tp': 15}\n",
      "==============================\n",
      "Split: 1\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0100, prevision: 1.00, recall: 0.99, f1: 0.99\n",
      "Training evaluation: {'tn': 7385, 'fp': 2, 'fn': 7, 'tp': 606}\n",
      "Testing loss: 0.2900, prevision: 1.00, recall: 0.30, f1: 0.46\n",
      "Testing evaluation: {'tn': 158, 'fp': 0, 'fn': 7, 'tp': 3}\n",
      "==============================\n",
      "Split: 2\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0100, prevision: 0.99, recall: 0.97, f1: 0.98\n",
      "Training evaluation: {'tn': 7400, 'fp': 7, 'fn': 15, 'tp': 578}\n",
      "Testing loss: 1.0500, prevision: 0.78, recall: 0.57, f1: 0.66\n",
      "Testing evaluation: {'tn': 95, 'fp': 10, 'fn': 27, 'tp': 36}\n",
      "==============================\n",
      "Split: 3\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0100, prevision: 1.00, recall: 0.99, f1: 0.99\n",
      "Training evaluation: {'tn': 7391, 'fp': 1, 'fn': 8, 'tp': 600}\n",
      "Testing loss: 0.4800, prevision: 0.70, recall: 0.52, f1: 0.60\n",
      "Testing evaluation: {'tn': 135, 'fp': 6, 'fn': 13, 'tp': 14}\n",
      "==============================\n",
      "Split: 4\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 1.00, recall: 0.98, f1: 0.99\n",
      "Training evaluation: {'tn': 7382, 'fp': 3, 'fn': 12, 'tp': 603}\n",
      "Testing loss: 0.0600, prevision: 0.00, recall: 0.00, f1: 0.00\n",
      "Testing evaluation: {'tn': 165, 'fp': 3, 'fn': 0, 'tp': 0}\n",
      "==============================\n",
      "Split: 5\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 1.00, recall: 0.97, f1: 0.98\n",
      "Training evaluation: {'tn': 7391, 'fp': 2, 'fn': 19, 'tp': 588}\n",
      "Testing loss: 0.2700, prevision: 0.00, recall: 0.00, f1: 0.00\n",
      "Testing evaluation: {'tn': 165, 'fp': 0, 'fn': 3, 'tp': 0}\n",
      "==============================\n",
      "Split: 6\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 1.00, recall: 0.98, f1: 0.99\n",
      "Training evaluation: {'tn': 7388, 'fp': 2, 'fn': 13, 'tp': 597}\n",
      "Testing loss: 0.0300, prevision: 0.00, recall: 0.00, f1: 0.00\n",
      "Testing evaluation: {'tn': 166, 'fp': 2, 'fn': 0, 'tp': 0}\n",
      "==============================\n",
      "Split: 7\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0100, prevision: 1.00, recall: 0.98, f1: 0.99\n",
      "Training evaluation: {'tn': 7399, 'fp': 2, 'fn': 11, 'tp': 588}\n",
      "Testing loss: 0.6800, prevision: 0.00, recall: 0.00, f1: 0.00\n",
      "Testing evaluation: {'tn': 142, 'fp': 17, 'fn': 9, 'tp': 0}\n",
      "==============================\n",
      "Split: 8\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 1.00, recall: 0.98, f1: 0.99\n",
      "Training evaluation: {'tn': 7402, 'fp': 0, 'fn': 13, 'tp': 585}\n",
      "Testing loss: 0.4400, prevision: 0.93, recall: 0.48, f1: 0.64\n",
      "Testing evaluation: {'tn': 138, 'fp': 1, 'fn': 15, 'tp': 14}\n",
      "==============================\n",
      "Split: 9\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0100, prevision: 1.00, recall: 0.99, f1: 0.99\n",
      "Training evaluation: {'tn': 7373, 'fp': 0, 'fn': 8, 'tp': 619}\n",
      "Testing loss: 1.5300, prevision: 0.83, recall: 0.16, f1: 0.27\n",
      "Testing evaluation: {'tn': 136, 'fp': 1, 'fn': 26, 'tp': 5}\n",
      "==============================\n",
      "Split: 10\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 0.99, recall: 0.98, f1: 0.99\n",
      "Training evaluation: {'tn': 7338, 'fp': 4, 'fn': 14, 'tp': 644}\n",
      "Testing loss: 0.5000, prevision: 0.00, recall: 0.00, f1: 0.00\n",
      "Testing evaluation: {'tn': 159, 'fp': 1, 'fn': 8, 'tp': 0}\n",
      "==============================\n",
      "Split: 11\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0100, prevision: 1.00, recall: 0.99, f1: 1.00\n",
      "Training evaluation: {'tn': 7333, 'fp': 1, 'fn': 4, 'tp': 662}\n",
      "Testing loss: 0.1800, prevision: 0.53, recall: 0.82, f1: 0.64\n",
      "Testing evaluation: {'tn': 149, 'fp': 8, 'fn': 2, 'tp': 9}\n",
      "==============================\n",
      "Split: 12\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 0.99, recall: 0.97, f1: 0.98\n",
      "Training evaluation: {'tn': 7335, 'fp': 7, 'fn': 22, 'tp': 636}\n",
      "Testing loss: 0.0100, prevision: 0.00, recall: 0.00, f1: 0.00\n",
      "Testing evaluation: {'tn': 168, 'fp': 0, 'fn': 0, 'tp': 0}\n",
      "==============================\n",
      "Split: 13\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0100, prevision: 1.00, recall: 0.98, f1: 0.99\n",
      "Training evaluation: {'tn': 7341, 'fp': 1, 'fn': 11, 'tp': 647}\n",
      "Testing loss: 0.1400, prevision: 0.83, recall: 0.62, f1: 0.71\n",
      "Testing evaluation: {'tn': 159, 'fp': 1, 'fn': 3, 'tp': 5}\n",
      "==============================\n",
      "Split: 14\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 0.99, recall: 0.98, f1: 0.98\n",
      "Training evaluation: {'tn': 7332, 'fp': 6, 'fn': 14, 'tp': 648}\n",
      "Testing loss: 0.8200, prevision: 0.64, recall: 0.32, f1: 0.42\n",
      "Testing evaluation: {'tn': 142, 'fp': 4, 'fn': 15, 'tp': 7}\n",
      "==============================\n",
      "Split: 15\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 1.00, recall: 0.97, f1: 0.99\n",
      "Training evaluation: {'tn': 7329, 'fp': 0, 'fn': 19, 'tp': 652}\n",
      "Testing loss: 0.3200, prevision: 0.00, recall: 0.00, f1: 0.00\n",
      "Testing evaluation: {'tn': 160, 'fp': 1, 'fn': 7, 'tp': 0}\n",
      "==============================\n",
      "Split: 16\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 0.97, recall: 0.95, f1: 0.96\n",
      "Training evaluation: {'tn': 7339, 'fp': 18, 'fn': 34, 'tp': 609}\n",
      "Testing loss: 0.6100, prevision: 0.57, recall: 0.42, f1: 0.48\n",
      "Testing evaluation: {'tn': 127, 'fp': 10, 'fn': 18, 'tp': 13}\n",
      "==============================\n",
      "Split: 17\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0100, prevision: 1.00, recall: 0.98, f1: 0.99\n",
      "Training evaluation: {'tn': 7347, 'fp': 1, 'fn': 16, 'tp': 636}\n",
      "Testing loss: 0.4400, prevision: 0.20, recall: 0.12, f1: 0.15\n",
      "Testing evaluation: {'tn': 156, 'fp': 4, 'fn': 7, 'tp': 1}\n",
      "==============================\n",
      "Split: 18\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 0.98, recall: 0.96, f1: 0.97\n",
      "Training evaluation: {'tn': 7347, 'fp': 10, 'fn': 26, 'tp': 617}\n",
      "Testing loss: 0.4500, prevision: 0.11, recall: 0.06, f1: 0.08\n",
      "Testing evaluation: {'tn': 144, 'fp': 8, 'fn': 15, 'tp': 1}\n",
      "==============================\n",
      "Split: 19\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 1.00, recall: 0.96, f1: 0.98\n",
      "Training evaluation: {'tn': 7338, 'fp': 3, 'fn': 29, 'tp': 630}\n",
      "Testing loss: 0.1100, prevision: 0.58, recall: 0.78, f1: 0.67\n",
      "Testing evaluation: {'tn': 154, 'fp': 5, 'fn': 2, 'tp': 7}\n",
      "==============================\n",
      "Split: 20\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 1.00, recall: 0.98, f1: 0.99\n",
      "Training evaluation: {'tn': 7342, 'fp': 0, 'fn': 12, 'tp': 646}\n",
      "Testing loss: 0.6500, prevision: 0.14, recall: 0.04, f1: 0.06\n",
      "Testing evaluation: {'tn': 138, 'fp': 6, 'fn': 23, 'tp': 1}\n",
      "==============================\n",
      "Split: 21\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0300, prevision: 0.98, recall: 0.94, f1: 0.96\n",
      "Training evaluation: {'tn': 7307, 'fp': 11, 'fn': 44, 'tp': 638}\n",
      "Testing loss: 1.2400, prevision: 1.00, recall: 0.37, f1: 0.54\n",
      "Testing evaluation: {'tn': 130, 'fp': 0, 'fn': 24, 'tp': 14}\n",
      "==============================\n",
      "Split: 22\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0300, prevision: 0.98, recall: 0.95, f1: 0.97\n",
      "Training evaluation: {'tn': 7266, 'fp': 14, 'fn': 35, 'tp': 685}\n",
      "Testing loss: 0.0100, prevision: 0.00, recall: 0.00, f1: 0.00\n",
      "Testing evaluation: {'tn': 167, 'fp': 1, 'fn': 0, 'tp': 0}\n",
      "==============================\n",
      "Split: 23\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 0.99, recall: 0.96, f1: 0.97\n",
      "Training evaluation: {'tn': 7283, 'fp': 8, 'fn': 29, 'tp': 680}\n",
      "Testing loss: 0.1300, prevision: 0.00, recall: 0.00, f1: 0.00\n",
      "Testing evaluation: {'tn': 166, 'fp': 0, 'fn': 2, 'tp': 0}\n",
      "==============================\n",
      "Split: 24\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0300, prevision: 0.98, recall: 0.93, f1: 0.95\n",
      "Training evaluation: {'tn': 7298, 'fp': 13, 'fn': 48, 'tp': 641}\n",
      "Testing loss: 0.2200, prevision: 0.20, recall: 0.20, f1: 0.20\n",
      "Testing evaluation: {'tn': 150, 'fp': 8, 'fn': 8, 'tp': 2}\n",
      "==============================\n",
      "Split: 25\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0300, prevision: 0.98, recall: 0.96, f1: 0.97\n",
      "Training evaluation: {'tn': 7289, 'fp': 12, 'fn': 31, 'tp': 668}\n",
      "Testing loss: 0.1500, prevision: 0.50, recall: 0.12, f1: 0.20\n",
      "Testing evaluation: {'tn': 159, 'fp': 1, 'fn': 7, 'tp': 1}\n",
      "==============================\n",
      "Split: 26\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0300, prevision: 0.98, recall: 0.95, f1: 0.96\n",
      "Training evaluation: {'tn': 7292, 'fp': 16, 'fn': 36, 'tp': 656}\n",
      "Testing loss: 0.1300, prevision: 0.90, recall: 0.60, f1: 0.72\n",
      "Testing evaluation: {'tn': 152, 'fp': 1, 'fn': 6, 'tp': 9}\n",
      "==============================\n",
      "Split: 27\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0300, prevision: 0.98, recall: 0.93, f1: 0.95\n",
      "Training evaluation: {'tn': 7280, 'fp': 13, 'fn': 52, 'tp': 655}\n",
      "Testing loss: 0.6600, prevision: 0.86, recall: 0.26, f1: 0.40\n",
      "Testing evaluation: {'tn': 144, 'fp': 1, 'fn': 17, 'tp': 6}\n",
      "==============================\n",
      "Split: 28\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0300, prevision: 0.98, recall: 0.95, f1: 0.96\n",
      "Training evaluation: {'tn': 7264, 'fp': 13, 'fn': 37, 'tp': 686}\n",
      "Testing loss: 0.0100, prevision: 1.00, recall: 1.00, f1: 1.00\n",
      "Testing evaluation: {'tn': 162, 'fp': 0, 'fn': 0, 'tp': 6}\n",
      "==============================\n",
      "Split: 29\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 1.00, recall: 0.98, f1: 0.99\n",
      "Training evaluation: {'tn': 7289, 'fp': 0, 'fn': 15, 'tp': 696}\n",
      "Testing loss: 0.3000, prevision: 0.38, recall: 0.27, f1: 0.32\n",
      "Testing evaluation: {'tn': 152, 'fp': 5, 'fn': 8, 'tp': 3}\n",
      "==============================\n",
      "Split: 30\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 0.99, recall: 0.97, f1: 0.98\n",
      "Training evaluation: {'tn': 7271, 'fp': 7, 'fn': 25, 'tp': 697}\n",
      "Testing loss: 1.0500, prevision: 0.95, recall: 0.39, f1: 0.55\n",
      "Testing evaluation: {'tn': 121, 'fp': 1, 'fn': 28, 'tp': 18}\n",
      "==============================\n",
      "Split: 31\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 0.99, recall: 0.97, f1: 0.98\n",
      "Training evaluation: {'tn': 7228, 'fp': 10, 'fn': 21, 'tp': 741}\n",
      "Testing loss: 1.1600, prevision: 0.88, recall: 0.25, f1: 0.39\n",
      "Testing evaluation: {'tn': 139, 'fp': 1, 'fn': 21, 'tp': 7}\n",
      "==============================\n",
      "Split: 32\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 0.99, recall: 0.97, f1: 0.98\n",
      "Training evaluation: {'tn': 7212, 'fp': 6, 'fn': 27, 'tp': 755}\n",
      "Testing loss: 0.6200, prevision: 0.00, recall: 0.00, f1: 0.00\n",
      "Testing evaluation: {'tn': 162, 'fp': 1, 'fn': 5, 'tp': 0}\n",
      "==============================\n",
      "Split: 33\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 0.99, recall: 0.98, f1: 0.98\n",
      "Training evaluation: {'tn': 7227, 'fp': 8, 'fn': 18, 'tp': 747}\n",
      "Testing loss: 0.2100, prevision: 0.47, recall: 0.78, f1: 0.58\n",
      "Testing evaluation: {'tn': 151, 'fp': 8, 'fn': 2, 'tp': 7}\n",
      "==============================\n",
      "Split: 34\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0400, prevision: 0.97, recall: 0.93, f1: 0.95\n",
      "Training evaluation: {'tn': 7202, 'fp': 24, 'fn': 53, 'tp': 721}\n",
      "Testing loss: 0.8100, prevision: 0.25, recall: 0.29, f1: 0.27\n",
      "Testing evaluation: {'tn': 136, 'fp': 15, 'fn': 12, 'tp': 5}\n",
      "==============================\n",
      "Split: 35\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0300, prevision: 0.99, recall: 0.97, f1: 0.98\n",
      "Training evaluation: {'tn': 7211, 'fp': 10, 'fn': 25, 'tp': 754}\n",
      "Testing loss: 0.2900, prevision: 0.54, recall: 0.65, f1: 0.59\n",
      "Testing evaluation: {'tn': 137, 'fp': 11, 'fn': 7, 'tp': 13}\n",
      "==============================\n",
      "Split: 36\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0100, prevision: 1.00, recall: 0.99, f1: 1.00\n",
      "Training evaluation: {'tn': 7234, 'fp': 1, 'fn': 6, 'tp': 759}\n",
      "Testing loss: 0.5700, prevision: 0.67, recall: 0.20, f1: 0.31\n",
      "Testing evaluation: {'tn': 157, 'fp': 1, 'fn': 8, 'tp': 2}\n",
      "==============================\n",
      "Split: 37\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0300, prevision: 0.99, recall: 0.93, f1: 0.96\n",
      "Training evaluation: {'tn': 7225, 'fp': 10, 'fn': 54, 'tp': 711}\n",
      "Testing loss: 0.3100, prevision: 0.42, recall: 0.50, f1: 0.46\n",
      "Testing evaluation: {'tn': 141, 'fp': 11, 'fn': 8, 'tp': 8}\n",
      "==============================\n",
      "Split: 38\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 0.99, recall: 0.98, f1: 0.98\n",
      "Training evaluation: {'tn': 7224, 'fp': 10, 'fn': 18, 'tp': 748}\n",
      "Testing loss: 0.0700, prevision: 0.90, recall: 0.75, f1: 0.82\n",
      "Testing evaluation: {'tn': 155, 'fp': 1, 'fn': 3, 'tp': 9}\n",
      "==============================\n",
      "Split: 39\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0300, prevision: 0.98, recall: 0.96, f1: 0.97\n",
      "Training evaluation: {'tn': 7217, 'fp': 16, 'fn': 28, 'tp': 739}\n",
      "Testing loss: 0.3900, prevision: 0.26, recall: 0.75, f1: 0.39\n",
      "Testing evaluation: {'tn': 143, 'fp': 17, 'fn': 2, 'tp': 6}\n",
      "==============================\n",
      "Split: 40\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0300, prevision: 0.98, recall: 0.97, f1: 0.98\n",
      "Training evaluation: {'tn': 7235, 'fp': 12, 'fn': 24, 'tp': 729}\n",
      "Testing loss: 0.8100, prevision: 0.91, recall: 0.31, f1: 0.47\n",
      "Testing evaluation: {'tn': 135, 'fp': 1, 'fn': 22, 'tp': 10}\n",
      "==============================\n",
      "Split: 41\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 0.99, recall: 0.98, f1: 0.99\n",
      "Training evaluation: {'tn': 7238, 'fp': 9, 'fn': 13, 'tp': 740}\n",
      "Testing loss: 0.9700, prevision: 0.00, recall: 0.00, f1: 0.00\n",
      "Testing evaluation: {'tn': 132, 'fp': 32, 'fn': 4, 'tp': 0}\n",
      "==============================\n",
      "Split: 42\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 0.99, recall: 0.98, f1: 0.99\n",
      "Training evaluation: {'tn': 7270, 'fp': 4, 'fn': 15, 'tp': 711}\n",
      "Testing loss: 0.6800, prevision: 0.00, recall: 0.00, f1: 0.00\n",
      "Testing evaluation: {'tn': 148, 'fp': 6, 'fn': 14, 'tp': 0}\n",
      "==============================\n",
      "Split: 43\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 0.99, recall: 0.97, f1: 0.98\n",
      "Training evaluation: {'tn': 7266, 'fp': 6, 'fn': 19, 'tp': 709}\n",
      "Testing loss: 1.3900, prevision: 0.67, recall: 0.19, f1: 0.30\n",
      "Testing evaluation: {'tn': 122, 'fp': 4, 'fn': 34, 'tp': 8}\n",
      "==============================\n",
      "Split: 44\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0300, prevision: 0.98, recall: 0.94, f1: 0.96\n",
      "Training evaluation: {'tn': 7231, 'fp': 14, 'fn': 49, 'tp': 706}\n",
      "Testing loss: 0.9600, prevision: 0.08, recall: 0.04, f1: 0.05\n",
      "Testing evaluation: {'tn': 132, 'fp': 11, 'fn': 24, 'tp': 1}\n",
      "==============================\n",
      "Split: 45\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0300, prevision: 0.99, recall: 0.96, f1: 0.97\n",
      "Training evaluation: {'tn': 7216, 'fp': 11, 'fn': 28, 'tp': 745}\n",
      "Testing loss: 0.5800, prevision: 0.30, recall: 0.60, f1: 0.40\n",
      "Testing evaluation: {'tn': 132, 'fp': 21, 'fn': 6, 'tp': 9}\n",
      "==============================\n",
      "Split: 46\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0300, prevision: 0.96, recall: 0.94, f1: 0.95\n",
      "Training evaluation: {'tn': 7199, 'fp': 27, 'fn': 45, 'tp': 729}\n",
      "Testing loss: 0.1700, prevision: 0.89, recall: 0.57, f1: 0.70\n",
      "Testing evaluation: {'tn': 153, 'fp': 1, 'fn': 6, 'tp': 8}\n",
      "==============================\n",
      "Split: 47\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0300, prevision: 0.98, recall: 0.96, f1: 0.97\n",
      "Training evaluation: {'tn': 7207, 'fp': 15, 'fn': 32, 'tp': 746}\n",
      "Testing loss: 0.1200, prevision: 0.00, recall: 0.00, f1: 0.00\n",
      "Testing evaluation: {'tn': 161, 'fp': 5, 'fn': 2, 'tp': 0}\n",
      "==============================\n",
      "Split: 48\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0200, prevision: 0.99, recall: 0.96, f1: 0.98\n",
      "Training evaluation: {'tn': 7223, 'fp': 8, 'fn': 27, 'tp': 742}\n",
      "Testing loss: 0.2100, prevision: 0.82, recall: 0.89, f1: 0.85\n",
      "Testing evaluation: {'tn': 126, 'fp': 7, 'fn': 4, 'tp': 31}\n",
      "==============================\n",
      "Split: 49\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0300, prevision: 0.99, recall: 0.95, f1: 0.97\n",
      "Training evaluation: {'tn': 7222, 'fp': 4, 'fn': 40, 'tp': 734}\n",
      "Testing loss: 0.0200, prevision: 0.00, recall: 0.00, f1: 0.00\n",
      "Testing evaluation: {'tn': 167, 'fp': 1, 'fn': 0, 'tp': 0}\n",
      "==============================\n",
      "Split: 50\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0300, prevision: 0.98, recall: 0.95, f1: 0.97\n",
      "Training evaluation: {'tn': 7231, 'fp': 15, 'fn': 34, 'tp': 720}\n",
      "Testing loss: 0.2400, prevision: 0.40, recall: 0.89, f1: 0.55\n",
      "Testing evaluation: {'tn': 147, 'fp': 12, 'fn': 1, 'tp': 8}\n",
      "==============================\n",
      "Split: 51\n",
      "----------\n",
      "Epoch [30/30]\n",
      "Training loss: 0.0300, prevision: 0.99, recall: 0.93, f1: 0.96\n",
      "Training evaluation: {'tn': 7292, 'fp': 7, 'fn': 47, 'tp': 654}\n",
      "Testing loss: 0.0600, prevision: 0.00, recall: 0.00, f1: 0.00\n",
      "Testing evaluation: {'tn': 162, 'fp': 6, 'fn': 0, 'tp': 0}\n",
      "==============================\n"
     ]
    }
   ],
   "source": [
    "# Create time series splits for cross-validation.\n",
    "splits = []\n",
    "dataset_size = df_x.shape[0]\n",
    "train_size = 8000\n",
    "test_size = 168\n",
    "input_size = feature.shape[1]\n",
    "for i in range(train_size, dataset_size, test_size):\n",
    "    start = i - train_size\n",
    "    end = i + test_size\n",
    "    if (end >= dataset_size): break\n",
    "    train_index = range(start, i)\n",
    "    test_index = range(i, end)\n",
    "    splits.append((list(train_index), list(test_index)))\n",
    "    \n",
    "# Cross-validate the model for every split\n",
    "precision_list = []\n",
    "recall_list = []\n",
    "f1_list = []\n",
    "for i in range(len(splits)):\n",
    "    print(f\"Split: {i}\")\n",
    "    dataset_train = SmellPittsburghDataset(feature=feature[splits[i][0]], label=label[splits[i][0]])\n",
    "    dataset_test = SmellPittsburghDataset(feature=feature[splits[i][1]], label=label[splits[i][1]])\n",
    "    dataloader_train = DataLoader(dataset_train, batch_size=1024, shuffle=True)\n",
    "    dataloader_test = DataLoader(dataset_test, batch_size=1024, shuffle=False)\n",
    "    model = DeepLogisticRegression(input_size)\n",
    "    criterion = nn.BCELoss()\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.01)\n",
    "    p_test, r_test, f1_test = train(model, criterion, optimizer, dataloader_train, dataloader_test)\n",
    "    precision_list.append(p_test)\n",
    "    recall_list.append(r_test)\n",
    "    f1_list.append(f1_test)\n",
    "    print(\"=\"*30)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fb69aff5-b448-441b-be08-5708321f13ce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "average precision: 0.44\n",
      "average recall: 0.32\n",
      "average f1-score: 0.34\n"
     ]
    }
   ],
   "source": [
    "# Print the overall performance\n",
    "print(\"average precision:\", round(np.mean(precision_list), 2))\n",
    "print(\"average recall:\", round(np.mean(recall_list), 2))\n",
    "print(\"average f1-score:\", round(np.mean(f1_list), 2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6665db32-9f9a-4fcf-97c7-d186fdd1e201",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
